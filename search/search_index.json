{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Hyperion Technical Documentation","text":"<p>Welcome to the Hyperion technical documentation pertaining to the high-performance computing (HPC) systems hosted by the DIPC Supercomputing Center.</p> <p>Please feel free to contact us with any questions, suggestions, or feedback you may have. Your input is highly valued and will help us continually improve our platform. As our site is under constant development, we encourage you to check back regularly for the latest updates and useful resources.</p> <p>This documentation will guide you through the essentials of using Hyperion and related services.</p>"},{"location":"#top-documentation-pages","title":"Top documentation pages","text":"<ul> <li>Startin with a new account - Information for new and existing users.</li> <li>Getting Started - Information for new and existing users.</li> <li>Getting Help - How to get support.</li> <li>Job Queue Policy - Charge factors, run limits, submit limits.</li> <li>Sending Jobs (Slurm) - Comprehensive information on using the SLURM batch system to manage and run jobs on Hyperion.</li> </ul>"},{"location":"about/","title":"Humanum veluti corpus","text":""},{"location":"about/#flores-silva","title":"Flores silva","text":"<p>Lorem markdownum dispar laborant cubitique mutataeque animo. Ostendit Eumenides esse quae positaeque rogum Atreus quanto arma properandum. Ille turis, si vellera nympha. Uteri suspirat latus, non dies loqui huic. Regnat sed vincta gramine: bella indignatus erudit Atlantis, ad paret.</p> <pre><code>commandLifoSimm *= -3;\nif (3 == moodleBar) {\n    payload += bar;\n}\nin_logic_cyberspace = rss_it_dongle;\nbluetooth_core(-4);\n</code></pre>"},{"location":"about/#vires-residens-pastoribus-rapuere","title":"Vires residens pastoribus rapuere","text":"<p>Ceres simulat per mente, mihi aequora his parce dea neque ad nubes. Luctantiaque orbe advertens numeros certe praestantia prolem quoque; pater intus. Telis rubentem.</p>"},{"location":"about/#fera-forte-fertur-desubito-tellus-et-barbara","title":"Fera forte fertur desubito Tellus et barbara","text":"<p>Dardanidas albis vivit profecturas superas lacteus Pelates ignavus o cernunt animus manibus tradit ipse. Non sui illius amanti est pennis faveas, oraque, alvo. Pater accessisse et insigne aquas aliae spectemur castra fatebar iamque profanus Niobe concutit candescere letum et in est.</p> <p>Amat regemque inque Molpeus putares non viribus vidi docet, sum, Hectoris tum. Reliquit est antris ausa mites nudis, tot vidi rumorum Oenides iacentes filia cupies vulnera. Et Stheneleius marem recumbis, antiquum lucum. Ita idem merito labor e redeuntia iacet.</p>"},{"location":"about/#vagantem-abest","title":"Vagantem abest","text":"<p>Vultu volenti inportuna aevi, mollis pectusque manu Pagasaeus legebant vulnera caelestique ergo adclinavit admoveam et. At nuper, in me temptanda litora ingestoque micat cur Telamone fugit. Dimovit ipse, qua duceret; ite rapta laquei est minus viribus rabiem in teneo adit.</p> <pre><code>var newbieBrowserType = 20;\nvar algorithm = parameter_mouse_post;\nif (soapWindowsDrive &lt;= lamp_eps_clip * copy) {\n    default_drive = 5 - 1;\n}\nvar point = jpeg_white;\ngpu_ripcording = cellDirect.clockHitSpeakers(social.emoticon(desktop, 32,\n        dhcp)) / lanArtificialState;\n</code></pre> <p>Tu enim illi quoque, purpura spargit supponere illa. Mutant dignamque an dolor roganti texitur, fata silva tincta submissa, consederat.</p>"},{"location":"Training/3_first-job/","title":"First Example: Estimation of the valur of Pi with Monte Carlo methods","text":"<p>Before delving into the code, let's further explore the problem at hand. </p> <p>Pi (\u03c0) is a mathematical constant originally defined as the ratio of a circle's circumference to its diameter. It's a fundamental element in mathematics and appears in many formulas in all areas of mathematics and physics.</p> <p>However, \u03c0 is an irrational number, meaning it cannot be expressed as a simple fraction, and its decimal representation never ends or settles into a permanently repeating pattern. Although we usually approximate \u03c0 as 3.14159, its exact value is unknown.</p> <p>So how can we estimate it using a computer program? That's where the Monte Carlo method comes in.</p>"},{"location":"Training/3_first-job/#the-monte-carlo-method","title":"The Monte Carlo Method","text":"<p>The Monte Carlo method, named after the famous Monaco casino, is a statistical technique that uses random sampling to obtain numerical results. The underlying concept is to use randomness to solve problems that might be deterministic in principle.</p> <p>In this case, we'll be using the Monte Carlo method to estimate the value of \u03c0. Here's the idea:</p> <ol> <li> <p>Create a bounded area: Imagine a square with a side length of 1 unit. Now, inscribe a quarter-circle with a radius of 1 unit inside this square, like a pie wedge.</p> </li> <li> <p>Throw darts: We then \"throw darts\" at this square. The position (x, y) of each dart is determined randomly.</p> </li> <li> <p>Determine if the dart is inside the quarter-circle: For each dart, we compute whether it has landed inside the quarter-circle using the equation of a circle (x^2 + y^2 &lt; r^2, where r is the radius). If the dart lands inside the circle (x^2 + y^2 &lt; 1), we consider it a hit.</p> </li> <li> <p>Approximate \u03c0: We do this thousands or even millions of times. The ratio of the number of darts that hit inside the circle to the total number of darts thrown will approximately be \u03c0/4. </p> </li> </ol> <p>So, by multiplying this ratio by 4, we can approximate \u03c0!</p> <p>Now, this process is inherently parallel \u2014 each \"dart throw\" is an independent event, and we can perform multiple dart throws simultaneously. This is a perfect scenario for using a high-performance computing environment like SLURM. The more parallel processes we can run (and hence, the more darts we can throw), the better our approximation of \u03c0 can be. </p> <p>In the example script, we'll be generating these \"random dart throws\" using the Bash <code>$RANDOM</code> variable and then estimating \u03c0 in parallel tasks. By submitting this task to SLURM, we'll effectively be demonstrating a simple, yet powerful use case of HPC.</p> <p>Absolutely, we can integrate the use of <code>sbatch</code>, <code>salloc</code>, and <code>srun</code> into the Monte Carlo Pi estimation example. Here's the revised section:</p>"},{"location":"Training/3_first-job/#sample-batch-script","title":"Sample Batch Script","text":"<p>First, let's examine the SLURM batch script. We'll name our batch script <code>pi_estimation.sh</code>. It's important to note that the batch script is the primary way to submit jobs to the SLURM scheduler, and we submit this script using the <code>sbatch</code> command.</p> <p><pre><code>#!/bin/bash\n\n#SBATCH --job-name=PiEstimation\n#SBATCH --output=pi_job.%j.out\n#SBATCH --error=pi_job.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=4\n#SBATCH --time=01:00:00\n#SBATCH --mail-type=END,FAIL\n#SBATCH --mail-user=your-email@example.com\n\n# Load any necessary modules and activate the conda environment (if any)\n# module load python/3.8\n\n# Start the job steps\ndate;hostname;pwd\n\nfor i in $(seq 1 $SLURM_NTASKS); do\n(\n# Each task performs 10^6 trials\ntrials=1000000\ncount=0\n\nfor (( j=0; j&lt;trials; j++ )); do\nx=$(echo \"scale=4; $RANDOM/32767\" | bc -l)\ny=$(echo \"scale=4; $RANDOM/32767\" | bc -l)\n\n# Test if the point ($x, $y) lies within the unit circle\ninside=$( echo \"$x*$x + $y*$y &lt; 1.0\" | bc -l)\n\n# Increase count if the point is inside the circle\nif [[ $inside -eq 1 ]]; then\n((count++))\nfi\ndone\n\n# Estimate Pi based on the count and the number of trials\npi=$(echo \"scale=4; 4*$count/$trials\" | bc -l)\n\necho \"Task $i: Pi is approximately $pi\"\n) &amp;\ndone\n\n# Wait for all background tasks to finish\nwait\n</code></pre> Once you've written your batch script, you can submit it to SLURM using the <code>sbatch</code> command. The <code>sbatch</code> command reads a script file and submits the script as a job to SLURM. The script contains both the job parameters, specified on lines beginning with <code>#SBATCH</code>, and the job commands.</p> <pre><code>sbatch pi_estimation.sh\n</code></pre> <p>Here are the explanations for each <code>SBATCH</code> directive used in our batch script:</p> Directive Explanation <code>--job-name=PiEstimation</code> Sets the name of the job. This name appears in the job listings, making it easier to manage jobs. <code>--output=pi_job.%j.out</code> Sets the name of the standard output file for the job. <code>%j</code> is replaced with the job ID. <code>--error=pi_job.%j.err</code> Sets the name of the standard error file for the job. <code>%j</code> is replaced with the job ID. <code>--nodes=1</code> Specifies that the job requires 1 node. <code>--ntasks-per-node=4</code> Specifies the number of tasks to be initiated on each node. In this case, we have 4 tasks per node. <code>--time=01:00:00</code> Sets a limit on the total run time of the job. The job will be terminated if it runs longer than this limit. <code>--mail-type=END,FAIL</code> Sends an email when the job ends or fails. <code>--mail-user=your-email@example.com</code> Specifies the email address to receive job status updates. <p>Remember that all <code>SBATCH</code> directives must come before any executable line in your script. </p> <p>This batch script generates four parallel tasks, each performing a million trials to estimate the value of Pi. It demonstrates both the basic usage of SLURM and the application of parallel processing in solving computationally intensive problems. </p> <p>To submit this job script to SLURM, we would use the <code>sbatch</code> command:</p> <pre><code>sbatch pi_estimation.sh\n</code></pre> <p>This script, as well as subsequent outputs, error logs, and other relevant files, will be used throughout this course as we delve deeper into the powerful features of SLURM.</p>"},{"location":"Training/3_first-job/#interactive-job-with-salloc","title":"Interactive job with salloc","text":"<p>In some cases, you might want to run your jobs interactively, that is, get a shell on a compute node where you can type commands and run programs directly. This can be done using <code>salloc</code>.</p> <p>Here's how you could use <code>salloc</code> to start an interactive shell with 4 CPUs for one hour, and then run the Pi estimation program interactively:</p> <p><pre><code>salloc --ntasks=4 --time=01:00:00 bash pi_estimation.sh exit\n</code></pre> The <code>salloc</code> command allocates resources (in this case, 4 tasks for a duration of one hour) and starts a shell. In that shell, you can then directly execute the <code>pi_estimation.sh</code> script. Once you're done, don't forget to type <code>exit</code> to release the allocation.</p>"},{"location":"Training/3_first-job/#direct-job-step-execution-with-srun","title":"Direct job step execution with srun","text":"<p><code>srun</code> is another important command in SLURM. It allows you to run job steps directly without having to write a batch script. A job step is essentially a set of (possibly multiple) tasks that are co-scheduled across one or more nodes.</p> <p>In the context of our Pi estimation program, you could use <code>srun</code> to directly run the Pi estimation commands as a job step. However, as our script is a bit more complex (with loops and conditionals), it's not straightforward to do it with <code>srun</code> directly. Instead, we can wrap our core script into another script and then use <code>srun</code> to execute it: First, extract the core logic of our Pi estimation into a separate script, <code>core_pi.sh</code>:</p> <pre><code>#!/bin/bash\n\n# Each task performs 10^6 trials\ntrials=1000000\ncount=0\n\nfor (( j=0; j&lt;trials; j++ )); do\nx=$(echo \"scale=4; $RANDOM/32767\" | bc -l)\ny=$(echo \"scale=4; $RANDOM/32767\" | bc -l)\n\n# Test if the point ($x, $y) lies within the unit circle\ninside=$( echo \"$x*$x + $y*$y &lt; 1.0\" | bc -l)\n\n# Increase count if the point is inside the circle\nif [[ $inside -eq 1 ]]; then\n((count++))\nfi\ndone\n\n# Estimate Pi based on the count and the number of trials\npi=$(echo \"scale=4; 4*$count/$trials\" | bc -l)\n\necho \"Task $SLURM_PROCID: Pi is approximately $pi\"\n</code></pre> <p>Then, use <code>srun</code> to run this script as a job step, creating 4 tasks:</p> <pre><code>srun --ntasks=4 --time=01:00:00 bash core_pi.sh\n</code></pre> <p>Each of the 4 tasks will execute <code>core_pi.sh</code> separately, effectively running our Pi estimation in parallel.</p> <p>Remember, <code>srun</code> and <code>salloc</code> provide you with more flexibility and control over your job execution. You'll typically use <code>sbatch</code> for most of your jobs (especially long ones or ones that you want to schedule and forget), but <code>srun</code> and <code>salloc</code> can be very handy for quick or interactive jobs.</p>"},{"location":"Training/4_monitoring/","title":"Monitoring","text":"<p>As we progress through our exploration of SLURM, we now approach an essential aspect of job management - monitoring. After you've submitted your job to the HPC cluster (like our Pi estimation job from the previous example), you'll want to track its status. Monitoring allows you to understand your job's progress, check its resource usage, and help identify any potential issues that could affect its successful completion. SLURM provides several tools to assist you in job monitoring, including <code>squeue</code>, <code>sacct</code>, <code>sstat</code>, and <code>seff</code>. Let's dive into these commands, understand their usage, and see how we can leverage them for efficient job tracking.</p> <p>Absolutely. Here's a more comprehensive version of the <code>squeue</code> section.</p>"},{"location":"Training/4_monitoring/#squeue","title":"squeue","text":"<p>Think of <code>squeue</code> as your immediate source of information about your jobs. The <code>squeue</code> command displays information about jobs located in the SLURM scheduling queue.  Let's say you've just submitted your Pi estimation job, and you're keen to check its status. Here's how to do it:</p> <pre><code>squeue -u $USER\n</code></pre> <p>The <code>-u</code> flag followed by <code>$USER</code> allows you to filter the jobs belonging to your user. The output will be a table listing your jobs:</p> <pre><code>  JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n123456     debug pi_estim  username  R       0:25      1 node007\n</code></pre> <p>Let's decipher the output:</p> <ul> <li><code>JOBID</code>: Unique identifier of your job in the SLURM system.</li> <li><code>PARTITION</code>: The partition (or queue) where your job is placed.</li> <li><code>NAME</code>: The name of your job.</li> <li><code>USER</code>: The user who owns the job.</li> <li><code>ST</code>: The state of your job (<code>R</code> signifies that the job is currently running).</li> <li><code>TIME</code>: The time your job has been running.</li> <li><code>NODES</code>: The number of nodes your job is using.</li> <li><code>NODELIST(REASON)</code>: The specific node(s) your job is running on.</li> </ul> <p>If you wish to customize the display and show specific fields, you can use the <code>-o/--format</code> option. For example, to display the job ID, name, state, and the number of CPUs:</p> <pre><code>squeue -u $USER -o \"%.10i %.9P %.8j %.8u %.2t %.6D\"\n</code></pre> <p>The format option <code>%.10i %.9P %.8j %.8u %.2t %.6D</code> is used to customize the output. Here's what each of these specifiers means:</p> <ul> <li><code>%.10i</code>: Job ID with a field width of 10 characters.</li> <li><code>%.9P</code>: Partition name with a field width of 9 characters.</li> <li><code>%.8j</code>: Job name with a field width of 8 characters.</li> <li><code>%.8u</code>: User name with a field width of 8 characters.</li> <li><code>%.2t</code>: Job state with a field width of 2 characters.</li> <li><code>%.6D</code>: Number of nodes with a field width of 6 characters.</li> </ul> <p>Field width specifies the minimum number of characters to be printed. If the value to be printed is shorter than this number, the result is padded with blank spaces. The full list of available options can be found in the SLURM documentation.</p> <p>With the <code>squeue</code> command, you can stay updated with the status and progress of your job in the scheduling queue. In the next section, we will explore <code>sacct</code> and <code>sstat</code> to get more detailed information about the resource usage of your job.</p> <p>Sure, let's dive into more ways you can use <code>squeue</code> to monitor your jobs.</p>"},{"location":"Training/4_monitoring/#example-1-viewing-all-jobs-in-a-specific-partition","title":"Example 1: Viewing All Jobs in a Specific Partition","text":"<p>If you want to view all jobs currently in a specific partition, you can use the <code>-p</code> or <code>--partition</code> option. For example, to view all jobs in the <code>regular</code> partition:</p> <pre><code>squeue -p regular\n</code></pre> <p>This will show all jobs currently in the 'regular' partition, regardless of the user who submitted them.</p>"},{"location":"Training/4_monitoring/#example-2-viewing-jobs-in-specific-states","title":"Example 2: Viewing Jobs in Specific States","text":"<p>You can use <code>squeue</code> to display jobs in specific states. This can be particularly useful when you want to see how many jobs are running, pending, or completed. Use the <code>-t</code> or <code>--states</code> option followed by the state:</p> <pre><code>squeue -u $USER -t RUNNING\n</code></pre> <p>This command will show all your jobs currently running.</p> <p>Here are all the job states you can query using the <code>-t</code> or <code>--states</code> option of <code>squeue</code>:</p> <ul> <li> <p><code>PENDING</code> (or <code>PD</code>): Job is awaiting resource allocation. Your job might be pending because the resources it needs are not currently available, or it might be waiting in line due to job scheduling policies.</p> </li> <li> <p><code>RUNNING</code> (or <code>R</code>): Job currently has an allocation and is running.</p> </li> <li> <p><code>SUSPENDED</code> (or <code>S</code>): Job has an allocation, but execution has been suspended and CPU usage has been reduced to zero, often due to some system event.</p> </li> <li> <p><code>COMPLETING</code> (or <code>CG</code>): Job is in the process of completing. Some processes of the job are still running.</p> </li> <li> <p><code>COMPLETED</code> (or <code>CD</code>): Job has completed successfully.</p> </li> <li> <p><code>CONFIGURING</code> (or <code>CF</code>): Job has been allocated resources, but are being configured for the job.</p> </li> <li> <p><code>CANCELLED</code> (or <code>CA</code>): Job was explicitly cancelled by the user or system administrator. The job may or may not have been initiated.</p> </li> <li> <p><code>FAILED</code> (or <code>F</code>): Job terminated with non-zero exit code or other failure condition.</p> </li> <li> <p><code>TIMEOUT</code> (or <code>TO</code>): Job terminated upon reaching its time limit.</p> </li> <li> <p><code>PREEMPTED</code> (or <code>PR</code>): Job was preempted by a higher priority job.</p> </li> <li> <p><code>NODE_FAIL</code> (or <code>NF</code>): Job terminated due to failure of one or more allocated nodes.</p> </li> <li> <p><code>REVOKED</code> (or <code>RV</code>): Sibling job was unable to allocate resources and was revoked.</p> </li> <li> <p><code>SPECIAL_EXIT</code> (or <code>SE</code>): The job terminated in a condition that is interpreted as an exit code.</p> </li> </ul>"},{"location":"Training/4_monitoring/#example-3-sorting-jobs","title":"Example 3: Sorting Jobs","text":"<p><code>squeue</code> can also sort jobs based on various attributes such as priority, job ID, time left, etc. For instance, to sort your jobs based on their remaining time in descending order, use the <code>--sort</code> option:</p> <p><pre><code>squeue -u $USER --sort=-t\n</code></pre> This will display your jobs in descending order of remaining time (<code>-t</code>). The <code>-</code> sign before <code>t</code> is used for descending order. Without it, the jobs would be sorted in ascending order.</p> <p>These examples show the versatility of the <code>squeue</code> command and how it can be customized to get specific information about your jobs. Please remember to replace <code>$USER</code> with your username or keep it as is if you're running these commands directly in your terminal session. The full list of options is available in the SLURM documentation.</p>"},{"location":"Training/4_monitoring/#example-4-showing-extended-job-information","title":"Example 4: Showing Extended Job Information","text":"<p>If you want to see more detailed information about a particular job, including its start time, estimated end time, and the nodes it's running on, you can use the <code>-l</code> or <code>--long</code> option. </p> <p><pre><code>squeue -j 123456 --long\n</code></pre> This command will display extended information about the job with ID 123456 (replace it with your job ID). The output might look like this:&lt;</p> <pre><code>Tue May 23 10:15:39 2023\n   JOBID PARTITION     NAME     USER ST       START        END  NODES NODELIST(REASON)\n  123456     test  pi_estim    myuser  R 10:15:39 10:17:39      1 n0001\n</code></pre>"},{"location":"Training/4_monitoring/#example-5-displaying-job-information-in-parsable-format","title":"Example 5: Displaying Job Information in Parsable Format","text":"<p>For scripts or other automated tasks, you might want to obtain the job information in a parsable format. The <code>-h</code> or <code>--noheader</code> option can be used to suppress the header, and the <code>--Format</code> option allows you to specify the exact fields you need. For instance:</p> <p><pre><code>squeue -j 123456 --noheader --Format=jobid,username,state\n</code></pre> This will return a single line of output with the job ID, username, and state, separated by pipe characters. The output might look like:</p> <p><pre><code>123456|myuser|RUNNING\n</code></pre> In these examples, remember to replace <code>123456</code> with the ID of your job, and <code>myuser</code> with your username. The full list of format specifiers and options can be found in the SLURM documentation.</p>"},{"location":"Training/4_monitoring/#sacct","title":"sacct","text":"<p>The <code>sacct</code> command provides accounting data for all jobs and job steps in the SLURM workload manager. It's a treasure trove of information about your job's performance, offering insights into resource usage and time spent on different stages.</p> <p>To view the accounting data for a specific job, use the <code>-j</code> flag followed by the job id:</p> <p><pre><code>sacct -j 123456 --format=JobID,JobName,MaxRSS,Elapsed\n</code></pre> The <code>--format</code> option customizes the output, similar to the <code>squeue</code> command. In the above command, we are asking for the Job ID, Job Name, Maximum RSS memory used, and the Elapsed time of the job. A full list of available format options can be found in the SLURM documentation.</p> <p>The output might look like this:</p> <pre><code>       JobID    JobName     MaxRSS    Elapsed \n------------ ---------- ---------- ---------- \n123456           pi_estim   10000K   00:02:00\n</code></pre>"},{"location":"Training/4_monitoring/#sstat","title":"sstat","text":"<p><code>sstat</code> allows us to fetch the real-time status of a running job or step. This command gives us live updates on resource usage, which can be essential for optimizing your application.</p> <p>To get real-time stats of your running job:</p> <p><pre><code>sstat -j 123456 --format=JobID,AveCPU,AveRSS,AveVMSize\n</code></pre> Again, the <code>--format</code> option allows us to customize the output. This command displays the Job ID, average CPU usage, average resident set size (RSS) memory, and average virtual memory size.</p> <p>Here is a sample output:</p> <pre><code>  JobID     AveCPU     AveRSS    AveVMSize\n--------- ---------- ---------- -----------\n123456    00:02:00   100.00MB    500.00MB\n</code></pre> <p>The full list of format options can be found in the SLURM documentation.</p>"},{"location":"Training/4_monitoring/#seff","title":"seff","text":"<p><code>seff</code> provides a brief summary of the efficiency of your job. Although it's not part of the default SLURM installation, it's widely used due to its effectiveness.</p> <pre><code>seff 123456\n</code></pre> <p>This command will return something like this:</p> <pre><code>Job ID: 123456\nCluster: cluster_name\nUser/Group: user/group\nState: COMPLETED (exit code 0)\nCores: 4\nCPU Utilized: 00:08:00\nCPU Efficiency: 100.00% of 00:08:00 core-walltime\nWall-clock time: 00:02:00\nMemory Utilized: 100.00 MB\nMemory Efficiency: 25.00% of 400.00 MB\n</code></pre> <p>This output provides an overall picture of how efficiently your job utilized the allocated resources, which can be crucial in optimizing your application for an HPC environment. The use of these commands will give you a good understanding of how your job is performing and where there might be room for improvement.</p>"},{"location":"Training/4_monitoring/#scontrol","title":"scontrol","text":"<p><code>scontrol</code> is a utility provided by SLURM for administrative tasks, but it also has several functions that can be useful for users. One of these is the ability to display detailed information about a specific job. For example:</p> <pre><code>scontrol show job 123456\n</code></pre> <p>This command will show a detailed description of the job with ID 123456, including the time it was submitted, its current state, the partition it's running in, the resources it's using, and many other details. </p> <p>Here's a truncated example of what the output might look like:</p> <pre><code>JobId=123456 JobName=pi_estim\n   UserId=myuser(1000) GroupId=myuser(1000) MCS_label=N/A\n   Priority=4294901496 Nice=0 Account=(null) QOS=(null)\n   JobState=RUNNING Reason=None Dependency=(null)\n   Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0\n   ...\n</code></pre> <p>Note: The output of <code>scontrol show job</code> is quite long and has been truncated for brevity. To see all the information, run this command yourself with one of your job IDs.</p>"},{"location":"Training/4_monitoring/#sinfo","title":"sinfo","text":"<p>While <code>sinfo</code> is more typically used to display information about nodes and partitions, it can also be used to monitor the resources being used by jobs in real-time. For example:</p> <p><pre><code>sinfo -N -l\n</code></pre> This command will display a long format list of all nodes, showing which nodes are allocated to which jobs, the state of each node, how much of its resources are being used, and other details.</p> <p>Here's an example of what the output might look like:</p> <pre><code>Tue May 23 10:15:39 2023\nNODELIST   NODES PARTITION       STATE CPUS    S:C:T MEMORY TMP_DISK WEIGHT FEATURES REASON\nn0001          1  regular*   allocated   24   2:12:1  64000    48000      1   (null) none\n   JOBID PARTITION     NAME     USER ST       START        END  NODES NODELIST(REASON)\n  123456   regular pi_estim    myuser  R 10:15:39 10:17:39      1 n0001\n</code></pre> <p>In this example, you can see that node <code>n0001</code> is allocated to job 123456, which is currently running.  As always, remember to replace <code>123456</code> with your job ID and <code>myuser</code> with your username in these examples. And as always, the full list of options is available in the SLURM documentation.</p>"},{"location":"Training/5_constrains/","title":"Policies and constrains","text":"<p>In an HPC (High-Performance Computing) environment, imposing constraints plays a crucial role in effectively managing and optimizing job execution. These constraints collectively contribute to the overall effectiveness and fairness of job management in an HPC environment. By implementing appropriate constraints, HPC systems can enhance resource utilization, minimize job delays, and accommodate the diverse computational needs of multiple users and applications.</p> QoS/Partition Priority MaxWall MaxNodesPU MaxJobsPU MaxSubmitPU MaxTRES regular 200 1-00:00:00 24 50 test 500 00:10:00 2 2 2 long 200 2-00:00:00 24 20 xlong 200 8-00:00:00 6 14 large 200 2-00:00:00 40 6 xlarge 200 2-00:00:00 80 6 serial 200 2-00:00:00 24 120 cpu=1gpu=1node=1 <p>This is what each columns means:</p> <ul> <li>MaxWall: Maximum amount of time the job is allowed to run. \u00b41-00:00:00\u00b4 reads as one day or 24 hours.</li> <li>MaxNodesPU: Maximum amount of nodes user's jobs can use at a given time.</li> <li>MaxJobsPU: Maximum number of running jobs per user.</li> <li>MaxSubmitPU: Maximum number of jobs that can be submitted to the QoS/partition.</li> <li>MaxTRES: The maximum number of Trackable RESources (TRES) each job is able to use. </li> </ul>"},{"location":"Training/6_postrun/","title":"Post-Run Operations","text":"<p>Once the work is finished we should move the generated data to our home directory under /dipc or to a local folder. This is done for two main reasons:</p> <ol> <li>The scrath is not backed up, so in case there is a problem with the filesystem, the stored data will be lost.</li> <li>The /scratch file system is designed for performance rather than reliability. When the occupancy goes above 80% the BeeGFS filesystem shows a performance degradation that affects all users.</li> </ol>"},{"location":"Training/6_postrun/#analyzing-job-performance-with-seff","title":"Analyzing job performance with seff","text":"<p>SLURM provides a tool called <code>seff</code> to check the memory utilization and CPU efficiency for completed jobs. Note that for running and failed jobs, the efficiency numbers reported by seff are not reliable so please use this tool only for successfully completed jobs:</p> <pre><code>seff &lt;job_id&gt;\n</code></pre>"},{"location":"Training/7_examples/","title":"Examples","text":"<p>Here we collect different usefull sbatch script examples.</p> Serial <p> Serial jobs are tasks that run sequentially on a single processor without parallelization. They are used for workloads that can't be easily parallelized or don't benefit from parallel processing. </p> <pre>\n#!/bin/bash\n#SBATCH --job-name=serial_job\n#SBATCH --output=output.log\n#SBATCH --error=error.log\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1\n\necho \"Running serial job...\"\n# Your serial job commands go here\n    </pre> MPI <p> MPI (Message Passing Interface) is a parallel programming model for distributed memory systems. It enables programs to run across multiple processors, communicating via message passing. </p> <pre>\n#!/bin/bash\n#SBATCH --partition=regular\n#SBATCH --job-name=JOB_NAME\n#SBATCH --cpus-per-task=1\n#SBATCH --mem=200gb\n#SBATCH --nodes=8\n#SBATCH --ntasks-per-node=48\n\nmodule load program/program_version\n\nmpirun -np $SLURM_NTASKS binaryi &lt; input \n</pre> OpenMP <p> For a OpenMP application the number of threads can be controlled defining the ``OMP_NUM_THREADS`` or SLURM's ``--cpus-per-task`` job directive. If this variable is not defined, the number of threads created will be equal to the amount of cores reserved in your cpuset, that is, the number of cores requested in the batch script. </p> <pre>\n#!/bin/bash\n#SBATCH --partition=regular\n#SBATCH --job-name=JOB_NAME\n#SBATCH --cpus-per-task=48\n#SBATCH --mem=200gb\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1\n\nmodule load program/program_version\n\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n\nbinary &lt; input\n</pre> Hybrid (MPI+OpenMP) <p> Hybrid parallelization, combining MPI (Message Passing Interface) and OpenMP, is a powerful approach for harnessing the computational capabilities of both distributed and shared memory systems. In this paradigm, MPI is used for inter-node communication, enabling data exchange and synchronization between distributed processes, while OpenMP is employed within each node for intra-node parallelization across multiple threads. </p> <pre>\n#!/bin/bash\n#SBATCH --partition=regular\n#SBATCH --job-name=JOB_NAME\n#SBATCH --cpus-per-task=4\n#SBATCH --mem=200gb\n#SBATCH --nodes=2\n#SBATCH --ntasks-per-node=12\n\nmodule load program/program_version\n\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\nmpirun -np $SLURM_NTASKS binaryi &lt; input\n</pre> GPU jobs <p>GPU jobs refer to tasks or applications that utilize the computational power of Graphics Processing Units (GPUs) for accelerated processing. GPU jobs are commonly used for deep learning, scientific simulations, data analytics, and other computationally intensive tasks that can benefit from parallel processing on GPUs. By leveraging the power of GPUs, these jobs can achieve significant performance gains compared to running on CPUs alone.One can request the usage of GPUs by adding ``#SBATCH --gres=gpu:p40:X`` to the submision script. In the following example we request 2 GPUs per node </p> <pre>\n#!/bin/bash\n#SBATCH --partition=regular\n#SBATCH --job-name=GROMACS_job\n#SBATCH --mem=200gb\n#SBATCH --cpus-per-task=1\n#SBATCH --nodes=2\n#SBATCH --ntasks-per-node=8\n#SBATCH --gres=gpu:p40:2\n#SBATCH --output=%x-%j.out\n#SBATCH --error=%x-%j.err\n\nmodule load GROMACS/2020-fosscuda-2019b\n\nsrun gmx_mpi mdrun -ntomp $SLURM_CPUS_PER_TASK -nb auto -bonded auto -pme auto -gpu_id 01 -s input.tpr\n</pre> Job Array <p>SLURM job arrays allow users to submit and manage a group of related jobs as a single entity. A job array consists of multiple tasks that are similar in nature but have different input data or parameters. SLURM handles the task distribution, resource allocation, and job dependencies automatically. They simplify job submission and management, improve efficiency, and provide better control over large-scale job execution in HPC environments. </p> <pre>\n#!/bin/bash\n#SBATCH --partition=regular\n#SBATCH --job-name=ARRAY_JOB\n#SBATCH --time=00:10:00\n#SBATCH --nodes=1              # nodes per instance\n#SBATCH --ntasks=1             # tasks per instance\n#SBATCH --array=0-9           # instance indexes\n#SBATCH --output=%x-%j.out\n#SBATCH --error=%x-%j.err\n\necho \"Slurm job id is ${SLURM_JOB_ID}\"\necho \"Array job id is ${SLURM_ARRAY_JOB_ID}\"\necho \"Instance index is ${SLURM_ARRAY_TASK_ID}.\"    \n</pre> Dependency chains <p>Job dependencies are used to defer the start of a job until some dependencies have been satisfied. Job dependencies can be defined using the ``--dependency`` argument of the ``sbatch`` command:      ``#SBATCH --dependency=\"dependency_type\"``          Available dependencies are:         - ``after:jobID`` job starts when job with ``jobID`` begun execution.         - ``afterany:jobID`` job starts when job with ``jobID`` terminates.         - ``aferok:jobID`` job starts when job with ``jobID`` terminates successfully.         - ``afternook:jobID`` job starts when job with ``jobID`` terminates with non-zero status.         - ``singleton:jobID`` jobs starts when any previously job with the same job name and user terminates. This can be used to chain restartable jobs.        <pre>\n#!/bin/bash\n#SBATCH --partition=regular\n#SBATCH --job-name=ARRAY_JOB\n#SBATCH --time=00:10:00\n#SBATCH --nodes=1              # nodes per instance\n#SBATCH --ntasks=1             # tasks per instance\n#SBATCH --array=0-9           # instance indexes\n#SBATCH --output=%x-%j.out\n#SBATCH --error=%x-%j.err\n\necho \"Slurm job id is ${SLURM_JOB_ID}\"\necho \"Array job id is ${SLURM_ARRAY_JOB_ID}\"\necho \"Instance index is ${SLURM_ARRAY_TASK_ID}.\"\n</pre>"},{"location":"Training/advanced/","title":"Advanced","text":""},{"location":"Training/advanced/#scalability-experiments","title":"Scalability experiments","text":"<p>Scaling experiments are crucial for assessing code scalability and parallel performance. They involve systematically varying computational resources to gain insights into code behavior under different workloads. These experiments provide valuable information, identify limitations, and drive improvements.</p> <p>Results serve two key purposes. Firstly, they diagnose code performance by analyzing execution times and speedup as resources increase. This helps identify bottlenecks and optimize code for better performance.</p> <p>Secondly, scaling results are necessary for resource allocation requests. Funding agencies require evidence of code scalability and performance to assess resource requirements and potential impact.</p> <p>Visualizations like speedup and efficiency plots effectively present scaling results. They illustrate execution time improvement and resource utilization effectiveness.</p> <p>In conclusion, scaling experiments are vital for understanding code scalability and parallel performance. They inform optimization efforts and support resource allocation requests. Visualizations aid in communicating results effectively. </p> <p></p> Determine best performance from a scalability study     Consider the following scalability plot for a random application.    At what point would you consider to be peak performance in this example. <ol> <li> The point where performance gains are no longer linear</li> <li> The apex of the curve </li> <li> The maximum core count</li> <li> None of the above</li> </ol> You may find that a scalability graph may vary if you ran the same code on a different machine. Why?   Show Solution <ol> <li>     No, the performance is still increasing, at this point we are no longer achieving perfect scalability.</li> <li>     Yes, the performance peaks at this location, and one cannot get higher speed up with this set up.</li> <li>     No, peak performance has already been achieved, and increasing the core count will onlt reduce performance.</li> <li>     No, although you can run extra benchmarks to find the exact number of cores at which the inflection point truly lies, there is no real purpose for doing so.</li> </ol> <p>     Tying into the answer for #4, if you produce scalability studies on different machines, they will be different because of the different setup, hardware of the machine. You are never going to get two scalability studies which are identical, but they will agree to some point. </p> <p>8_advanced</p>"},{"location":"Training/introduction/1_introduction/","title":"Introduction","text":"<p>In the modern era of research, High-Performance Computing (HPC) has emerged as a cornerstone, powering groundbreaking innovations and discoveries. It provides the robust computational capacity necessary for handling highly complex and data-intensive tasks. Whether it's climate modeling, genomic research, artificial intelligence, or particle physics, HPC is the engine driving these high-stake computations.</p> <p>However, to maximize the utility of an HPC system and ensure its resources are used efficiently, we require a mechanism that can manage, allocate, and schedule computational tasks. This is where workload managers, or job schedulers, step in.</p>"},{"location":"Training/introduction/1_introduction/#role-and-importance-of-workload-managers","title":"Role and Importance of Workload Managers","text":"<p>Workload managers orchestrate the computational tasks, also known as jobs, on the computing nodes within an HPC cluster. They are the conductors of the HPC symphony, optimizing the allocation of the system's resources.  Without a workload manager:</p> <ul> <li>Users would have to manually assign their jobs to specific nodes and make sure those nodes are not already in use. This is not only inefficient but also greatly increases the chance of error and system underutilization.</li> <li>There would be no mechanism to queue jobs. Hence, users would have to constantly monitor the system and manually launch jobs once resources become available.</li> <li>Handling the priorities for different jobs would be a nightmare. Some users might unfairly monopolize resources, while others might be left waiting for an unreasonably long time.</li> </ul> <p>In contrast, a workload manager automates these tasks and provides several significant advantages:</p> <ol> <li>Efficiency: It automates the job scheduling process, selecting the most suitable resources based on the job's requirements and the scheduling policies. This leads to increased system utilization and decreased job waiting times.</li> <li>Fairness: It manages job priorities based on factors such as user quotas and job sizes, ensuring that all users get their fair share of the system resources.</li> <li>Ease of Use: It provides users with commands to submit jobs, check their status, and cancel them if necessary. This makes it much easier for users to interact with the HPC system.</li> <li>Flexibility: It allows system administrators to implement policies that govern job priorities, system utilization, and resource allocation, providing a high degree of control over the system's operation.</li> </ol>"},{"location":"Training/introduction/1_introduction/#why-slurm","title":"Why SLURM?","text":"<p>Among the plethora of workload managers, SLURM (Simple Linux Utility for Resource Management) stands out and is widely adopted in the HPC community.  Here are the compelling reasons for choosing SLURM:</p> <ol> <li>Scalability and Performance: SLURM is built to scale and is capable of managing scheduling for some of the world's largest supercomputers, making it an excellent choice regardless of the size of the HPC system.</li> <li>Flexibility and Configurability: SLURM boasts high flexibility, providing numerous options that can be tweaked to match the specific needs of a particular system or set of users.</li> <li>Advanced Resource Management: SLURM supports a wide variety of resource types and allows for complex resource selection, ensuring that jobs receive the resources they need.</li> <li>Open Source and Active Development: Being open-source, SLURM benefits from the collective wisdom and efforts of a global community. It's continually improved, debugged, and updated, ensuring users have access to the latest features and performance improvements.</li> <li>Robustness and Reliability: SLURM provides automatic failover and fault-tolerant job management capabilities, ensuring the continuity of operations even when individual components fail.</li> </ol> <p>By the end of this course, we aim for you to be comfortable with using SLURM for managing your computational tasks, ranging from the creation and submission of jobs, monitoring their execution, to managing output files and analyzing job</p>"},{"location":"Training/workflow/2_workflow/","title":"Workflow","text":"<p>The typical workflow of a researcher using SLURM in an HPC environment involves several steps:</p> <ol> <li> <p>Connect to the System: Using Secure Shell (SSH), you connect to the login node of the HPC cluster.</p> </li> <li> <p>Prepare Your Work: This might include copying input files, writing scripts, or compiling programs.</p> </li> <li> <p>Job Submission: You write a batch script for SLURM that outlines the requirements and commands for your job, and submit this script to the scheduler.</p> </li> <li> <p>Monitor Your Job: You can keep track of your job's progress using several SLURM commands.</p> </li> <li> <p>Transfer Results: Once your job is completed, you can copy your output files from the compute node back to your local system.</p> </li> </ol> <p>In the following sections, we will delve into each of these steps, starting with a detailed walkthrough of a simple example.</p>"},{"location":"filesystem/","title":"Storage and Filesystem overview","text":""},{"location":"filesystem/#storage-system-usage","title":"Storage System Usage","text":""},{"location":"filesystem/#home","title":"Home","text":"<p>Your home directory is where you arrive by default when you login to the cluster or any access/login node. It is mounted on <code>/dipc/username</code>. Configuration files are stored here: <code>.bash_profile</code>, <code>.tcshrc</code>, <code>.vimrc</code>, etc. </p>"},{"location":"filesystem/#scratch","title":"scratch","text":"<p><code>/scratch</code> is a shared high performance storage that system provides access to large amounts of disk. It meant to be used as the work space for jobs.</p>"},{"location":"filesystem/#long-term-storage","title":"Long term storage","text":"<p>A filesystem designed for permanent data storage. </p> <p>Storage increase</p> <p>Although the storage capacity of <code>/scratch</code> should be large enough, if more is needed, contact us and we will assess the storage increase.</p>"},{"location":"filesystem/#backups","title":"Backups","text":"<p>Put here backup informations </p>"},{"location":"filesystem/data_transfer/","title":"Data transfer","text":"<p>One of the most common applications for securely transferring data between two hosts are Secure Copy (SCP) and Secure FTP (SFTP).</p> <p>To transfer files into or out of HPC systems using SCP or SFTP, you need a SSH client:</p> <ul> <li>GNU/Linux: command ssh, scp or sftp or a GUI tool like GFTP.</li> <li>Windows: GUI tools such as WinSCP,</li> <li>macOS: Command-line tools ssh, scp or sftp or a GUI tool like FileZilla.</li> </ul>"},{"location":"filesystem/home/","title":"Home","text":"<p>Your home directory is where you arrive by default when you login to the cluster or any access/login node. It is mounted on <code>/dipc/username</code>. It is not intended for permanent file storage as it has short capacity (2GB per user). Your shell refers to it as \u201c\u223c\u201d (tilde), and its absolute path is also stored in the environment variable $HOME. Your home directory is shared across all the HPC Systems at DIPC. The data stored here should be relatively small since it is meant to permanently store the most relevant information for your research. Note that various kinds of configuration files are also stored here: <code>.bash_profile</code>, <code>.tcshrc</code>, <code>.vimrc</code>, etc.</p> <p>Warning</p> <p>Remenber that <code>/dipc</code> filesystem is not exported to computing nodes, thus it is recomended to submit jobs from <code>/scratch</code>. </p>"},{"location":"filesystem/home/#quotas","title":"Quotas","text":"<p>information abour /home quotas</p>"},{"location":"filesystem/home/#backups","title":"Backups ??","text":""},{"location":"filesystem/long_storage/","title":"Long term storage","text":""},{"location":"filesystem/scratch/","title":"scratch filesystem","text":"<p><code>/scratch</code> is a shared high performance storage that system provides access to large amounts of disk. It meant to be used as the work space for jobs.</p> <p>Tip</p> <p>You should use it only to submit jobs from and to redirect all your I/O.</p>"},{"location":"filesystem/scratch/#check-your-scratch-usage","title":"Check your scratch usage","text":"<p>The storage offered by the <code>/scratch</code> filesystem is limited for each user. In case you want to check your your occupation, you can do it by running the following command:</p> <pre><code>beegfs-ctl --cfgFile=/etc/beegfs/beegfs-client-scratch.conf --getquota --uid $USER\n</code></pre> <p>Storage increase</p> <p>Although the storage capacity of <code>/scratch</code> should be large enough, if more is needed, contact us and we will assess the storage increase. </p>"},{"location":"general/","title":"General information","text":"<p>Test index.md</p>"},{"location":"general/account/","title":"Accounts","text":""},{"location":"general/account/#obtainin-a-user-account","title":"Obtainin a user account","text":"<p>In order to use Hyperion facilities, you need:</p> <ol> <li>A user account with an associated user login name (also called a username).</li> <li>You belong to a Basque university or institution.</li> <li>Access to a project with an allocation of computational or storage resources.</li> </ol>"},{"location":"general/account/#how-to-get-a-new-user-account","title":"How to get a New User account","text":"<p>If you don't possess a user account, you are encouraged to apply for an account.</p> <p>Please fill out the necessary form:</p> <ul> <li>Hyperion account form.</li> </ul> <p>Once completed, submit it either personally to our HPC Resource Manager or send it via email to support-cc@dipc.org.</p> <p>We kindly remind you that the approval of account requests is not automatic and is subject to our internal review process.</p>"},{"location":"general/account/#passwords","title":"Passwords","text":"<p>A user is given a username (also known as a login name) and associated password that permits that user to access Hyperion. This username/password pair may be used by a single individual only: passwords must not be shared with any other person.</p> <p>Passwords must be changed as soon as possible after exposure or suspected compromise. Exposure of passwords and suspected compromises must immediately be reported to the support team. </p>"},{"location":"general/account/#modifying-your-password","title":"Modifying Your Password","text":"<p>After your account is successfully created, a temporary password will be issued to you. For enhanced security and personalization, it is advisable to change this password at the earliest opportunity.</p> <p>To modify your password, simply execute the following command:</p> <pre><code>$ passwd \n</code></pre> <p>Upon entering the command, you will be prompted to type in your existing password. Following that, you will be asked to provide your new password.</p> <p>Please ensure that your new password complies with the following criteria:</p> <ul> <li>It must contain at least two uppercase characters.</li> <li>It must include at least two lowercase characters.</li> <li>It must have at least two digits.</li> <li>It must feature at least two special characters.</li> <li>It should be at least 8 characters in length.</li> <li>It should not be a repetition or overly similar to any of your previous passwords.</li> </ul> <p>These rules are put in place to ensure the security of your account and protect the integrity of our computing resources. We appreciate your understanding and cooperation.</p>"},{"location":"general/account/#forgotten-passwords","title":"Forgotten passwords","text":"<p>If you have forgotten your password, do not worry, send an email to technical support. You will be provided with a temporary password. You will have to change this password when you reconnect to Hyperion and you will have to meet the requirements explained above.</p>"},{"location":"general/getting_help/","title":"Getting help","text":"<p>Welcome to the Supercomputing Center, a keystone facility committed to powering your scientific endeavors. Our infrastructure is designed with user-centricity at its core, providing you with the necessary tools and support to facilitate your research. </p>"},{"location":"general/getting_help/#resources-and-support","title":"Resources and support","text":"<p>In case you encounter any difficulties or have specific questions, we have a dedicated support team ready to assist. Please direct all inquiries, suggestions, or concerns to our primary support channel via email at support-cc@dipc.org. </p> <p>Please note that we strongly recommend using our email support for a more structured and efficient resolution of your queries. While we understand the immediacy of phone calls or in-person visits, these methods may not allow for the most efficient handling of your requests due to our team's focus on maintaining and enhancing the Center's systems.</p> <p>Our Support team's operating hours are from Monday to Friday, 9:00 AM to 6:00 PM. We assure you that all inquiries will receive a timely and thorough response.</p> <p>The good ticket</p> <p>In order to ensure efficient timely resolution of issues include as much of the following as possible when making a request:</p> <ul> <li>Error messages</li> <li>JobID </li> <li>Location of relevant files such as input/output, job scripts, source code, or executables</li> <li>Output of module list</li> <li>Any steps you have tried</li> <li>Steps to reproduce</li> </ul>"},{"location":"general/getting_help/#software-and-application-request","title":"Software and Application request","text":"<p>Our High-Performance Computing (HPC) systems are equipped with an extensive range of utilities, applications, and programming libraries, supporting a wide spectrum of research needs.</p> <p>If there's a specific tool or software missing that you believe would enhance your scientific endeavor, we invite you to submit a request sending us the following form to support-cc@dipc.org:</p> <ul> <li>Software Request Form</li> </ul> <p>Your software suggestion will be evaluated based on its relevance, cost, effort, and potential benefits to the community.</p> <p>For more in-depth information on software management, please consult our Environment Modules section.</p>"},{"location":"general/getting_started/","title":"Getting started","text":"<p>!!! success \"About this page\" This document will guide you through the basics of using Hyperion.</p>"},{"location":"general/getting_started/#connecting-to-hyperion","title":"Connecting to Hyperion","text":""},{"location":"general/getting_started/#linux","title":"Linux","text":"<p>Most Linux distributions come with an SSH client pre-installed. The default SSH client is the OpenSSH client.</p> <p>Open a Terminal to establish a connection with the login node of any of out HPC systems:</p> <pre><code>$ ssh username@hyperion-login-01.sw.ehu.es\n$ ssh username@hyperion-login-02.sw.ehu.es\n</code></pre> <p>You will need to replace <code>username</code> with the username you were assigned.</p>"},{"location":"general/getting_started/#macos","title":"MacOS","text":"<p>MacOS also comes with a command-line SSH client installed by default. The usage of this client is identical to the usage described in the previous section for GNU/Linux.</p> <p>If you are using macOS and want to be able to run graphical applications on the clusters then you need to install the latest version of the XQuartz X Windows server.</p>"},{"location":"general/getting_started/#windows","title":"Windows","text":"<p>Windows users can use the built-in OpenSSH client starting from Windows 10 build 1809 or later. To enable the OpenSSH client, follow these steps:</p> <ul> <li>Open <code>Settings</code> and navigate to <code>Apps &gt; Optional Features</code>.</li> <li>Click <code>Add a feature</code> and search for <code>OpenSSH Client</code>.</li> <li>Select <code>Install</code>.</li> </ul> <p>Once installed, you can use the command prompt or PowerShell to connect to a remote server.</p> <p>Alternatively, you can download and install third-party SSH clients like PuTTY or MobaXterm.</p>"},{"location":"general/getting_started/#software","title":"Software","text":"<p>Hyperion supply a rich set of compilers, HPC utilities, programming libraries, development tools, debuggers/profilers, data and visualization tools. </p> <p>We provide a list of application specific documentation that are built by DIPC staff. </p> <p>Software can be accessed via <code>module</code> command. Go to Software section to read in depth about it.</p> <p>Something missing?</p> <p>If there is something missing that you would like to have on our systems, please submit a request and we will evaluate it for appropriateness, cost, effort, and benefit to the community.</p>"},{"location":"jobs/","title":"Running jobs Hyperion","text":"<p>Hyperion uses Slurm for cluster/resource management and job scheduling. Slurm is responsible for allocating resources to users, providing a framework for starting, executing and monitoring work on allocated resources and scheduling work for future execution.</p>"},{"location":"jobs/best_practices/","title":"Best Practices","text":"<p>Test index.md</p>"},{"location":"jobs/monitoring/","title":"Monitoring Jobs","text":""},{"location":"jobs/monitoring/#squeue","title":"squeue","text":"<p><code>squeue</code> provides information about jobs in Slurm scheduling queue, and is best used for viewing jobs and job step information for active jobs (PENDING, RUNNING, SUSPENDED). For more details on squeue refer to the squeue manual or run <code>squeue --help</code>, man squeue.</p> <pre><code>squeue -u $USER\n</code></pre> <p>To view all running jobs for the current user:</p> <pre><code>squeue --me -t RUNNING\n</code></pre> <p>To view all pending jobs for current user:</p> <pre><code>squeue --me -t PENDING\n</code></pre>"},{"location":"jobs/monitoring/#scancel","title":"scancel","text":"<p>Deletes your job. It takes the job identifier as a parameter.</p> <pre><code>scancel &lt;jobid&gt;\n</code></pre> <p>To cancel all the jobs for a user:</p> <pre><code>scancel -u &lt;username&gt;\n</code></pre> <p>To cancel all the running jobs for a user: </p> <pre><code>scancel -t RUNNING -u &lt;username&gt;\n</code></pre>"},{"location":"jobs/monitoring/#seff","title":"seff","text":"<p>SLURM provides a tool called <code>seff</code> to check the memory utilization and CPU efficiency for completed jobs. Note that for running and failed jobs, the efficiency numbers reported by <code>seff</code> are not reliable so please use this tool only for successfully completed jobs:</p> <pre><code>seff &lt;job_id&gt;\n</code></pre> <p>Tip</p> <p>It is recommended to use this command after launching some preliminary system work to see how many resources are being consumed, before launching a battery of calculations. Thus, in addition to reducing the waiting times for the reception of your work, you will help to maximize the resources of the calculation center</p>"},{"location":"jobs/monitoring/#sacct","title":"sacct","text":"<p><code>sacct</code> is used to report job or job step accounting information about active or completed jobs. For a complete list of sacct options please refer to the sacct manual or run man sacct</p> <p>Lists status info for a currently running job: </p> <pre><code>sstat --format=JobID,Nodelist -j &lt;jobid&gt;\n</code></pre>"},{"location":"jobs/monitoring/#email-notification","title":"Email notification","text":"<p>You may want to have SLURM send you email on certain events affecting your jobs. You can receive email to notify a job failure, completion, or if a job started. </p> <p>Add the following to your batch script to set the email address:</p> <pre><code>#SBATCH --mail-user=your@email.org\n</code></pre> <p>These are the different types of notifications:</p> <pre><code>#SBATCH --mail-type=BEGIN\n#SBATCH --mail-type=END\n#SBATCH --mail-type=FAIL\n#SBATCH --mail-type=ALL\n</code></pre>"},{"location":"jobs/queue_policy/","title":"Job queue policy","text":"<p>Here goes the queue policies and contrictions</p>"},{"location":"jobs/reservations/","title":"Reservations","text":"<p>Users can request a scheduled reservation of machine resources if their jobs have special needs that cannot be accommodated through the regular batch system. A reservation brings some portion of the machine to a specific user or project for an agreed upon duration. Typically this is used for interactive debugging at scale or real time processing linked to some experiment or event.</p> <p>Note</p> <p>It is not intended to be used to guarantee fast throughput for production runs.</p>"},{"location":"jobs/reservations/#fairshare","title":"Fairshare","text":"<p>For normal batch jobs, fairshare modification is done on a per job basis. For scheduled reservations the entire block of reserved time is charged regardless of the number of nodes used or time spent running jobs.</p>"},{"location":"jobs/reservations/#requesting-a-reservation","title":"Requesting a reservation","text":"<p>To reserve compute nodes, please ask for the least amount of resources you need and try to schedule reservations so as to minimize impact on other users. </p>"},{"location":"jobs/reservations/#viewing-reservations","title":"Viewing reservations","text":"<p>To view all reservations run 'scontrol show reservations', the output will consist of one entry per reservation name. Take a close look at the reservation fields such as <code>StartTime</code>, <code>EndTime</code>, <code>Duration</code>, <code>Nodes</code>, <code>Users</code>, <code>Accounts</code> to understand what the reservation.</p>"},{"location":"jobs/reservations/#using-a-reservation","title":"Using a reservation","text":"<p>Once your reservation request is approved and a reservation is placed on the system, to run jobs in the reservation, you can use the --reservation option on the submision script:</p> <pre><code>sbatch --reservation=&lt;reservation_name&gt;\n</code></pre>"},{"location":"jobs/slurm/","title":"SLURM","text":"<p>Slurm is an open source, fault-tolerant, and highly scalable cluster management and job batch system for large and small Linux clusters.</p> <p>Batch jobs are typically submitted using a batch script which is a text file containing a number of job directives and GNU/linux commands or utilities. Batch scripts are submitted to the SLURM, where they are queued awaiting free resources. </p> <pre><code>#!/bin/bash                                                          \n#SBATCH --partition=test\n#SBATCH --job-name=test_job\n#SBATCH --cpus-per-task=1\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1\n#SBATCH --time=00:10:00\n#SBATCH --mem=1Gb\n\necho \"Hello DIPC!\"\n</code></pre> <p>This batch script example can be read line by line as follows:</p> <ul> <li><code>#SBATCH --partition=test</code>: send job to the test partition.</li> <li><code>#SBATCH --job-name=test_job</code>: give a name to the job.</li> <li><code>#SBATCH --cpus-per-task=1</code>: number of cpus/threads per task/process.</li> <li><code>#SBATCH --nodes=1</code>: make a reservation of 1 node.</li> <li><code>#SBATCH --ntasks-per-node=1</code>: number of tasks/processes per node.</li> <li><code>#SBATCH --time=00:10:00</code>: requested walltime in DD-HH:MM:SS format.</li> <li><code>#SBATCH --mem=1GB</code>: requested memory per node in GB.</li> <li><code>echo \"Hello DIPC!\"</code>: actual piece of code we want to run.</li> </ul> <p>Tip</p> <p>If you do not know the amount of resources in terms of memory or time your jobs are going to need, you should overestimate this values in the first runs and tweak those values up as you learn how jobs behave. </p> <p>Once our batch script is prepared you can submit it as a batch job to the queue system.</p> <p>Tip</p> <p>If you do not redirect the output of your runs to a specific file, then the standard output will be redirected to a file that goes by the name <code>slurm-&lt;job_id&gt;.log</code>.</p>"},{"location":"software/","title":"Software and Environment","text":"<p>Test index.md</p>"},{"location":"software/applications/","title":"Applications","text":"<p>Hyperion is provided with a wide variety of pre-built applications, optimized for our systems. The primary way these are provided is through modules.</p> <p>Newbies</p> <p>A guide for a new users is provided to send jobs starting from zero.</p> <p>Requesting software</p> <p>If there's a specific tool or software missing that you believe would enhance your scientific endeavor, we invite you to submit a request form to support-cc@dipc.org:</p> <ul> <li>Software Request Form</li> </ul>"},{"location":"software/modules/","title":"Environment Modules","text":"<p>Environment modules provides a mechanism to dynamically modify a user's environment using modulefiles. A modulefile is a recipe required to load a particular application that may include setting environment variables; setting variables such as <code>PATH</code>, <code>LD_LIBRARY_PATH</code>, and <code>MANPATH</code> to include the location where an application is installed; loading dependent modules; and providing a brief description of the software.</p>"},{"location":"software/modules/#module-commands","title":"Module Commands","text":"<p>General usage:  <pre><code>module [switches] [subcommand] [subcommand-args]\n</code></pre></p> <p>Further reading:</p> <ul> <li><code>module --help</code></li> <li><code>man module</code></li> <li><code>man modulefile</code></li> <li>Environment Modules Documentation (note: some features may only be available in later versions than what is installed on NERSC systems)</li> </ul>"},{"location":"software/modules/#command-summary","title":"Command Summary","text":"Command Description <code>module list</code> List active modules in the user environment <code>module av[ail] [module]</code> List available modules in MODULEPATH <code>module add\\|load [module]</code> Load a module file in the user environment <code>module rm\\|unload [module]</code> Remove a loaded module from the user environment <code>module purge</code> Remove all modules from the user environment <code>module swap\\|switch [module1] [module2]</code> Replace <code>module1</code> with <code>module2</code> <code>module show\\|display [module]</code> Show content of commands performed by loading module file <code>module help [module]</code> Show help for a given module <code>module whatis [module]</code> A brief description of the module, generally single line <code>module use [-a] [path]</code> Prepend or Append path to MODULEPATH <code>module unuse [path]</code> Remove path from MODULEPATH <code>module keyword [text]</code> Search for keyword across all module files"},{"location":"software/modules/#module-usage","title":"Module Usage","text":"<p>Show availability of all modules containing a substring:</p> <pre><code>module avail -S &lt;substring&gt;\n</code></pre> <p>Loading a module to your current environment:</p> <pre><code>module load &lt;module-name&gt;\n</code></pre> <p>Tip</p> <p>If you load the name of a module (with no version), you will</p> <p>get the default version.</p> <pre><code>module load Python\n</code></pre> <p>To load a specific version use the full name:</p> <pre><code>module load Python/3.10.4-GCCcore-11.3.0\n</code></pre> <p>To see all the loaded module:</p> <pre><code>module list\n</code></pre> <p>Remove a module from the current environment:</p> <pre><code>module unload &lt;module-name&gt;\n</code></pre> <p>To purge/remove all modules:</p> <pre><code>module purge\n</code></pre>"},{"location":"staff/","title":"Our Team","text":"<p>For any issues, questions or suggestions, we strongly recommend reaching out to us via our general support email address at support-cc@dipc.org. However, if you need to contact a specific team member, you can find their contact information below.</p>"},{"location":"staff/#txomin-romero-director","title":"Txomin Romero - Director","text":"<p>Txomin is responsible for guiding our strategic direction. His responsibilities include:</p> <ul> <li>Overseeing hardware and software acquisitions</li> <li>Managing the general usage of DIPC computational resources</li> </ul> <p>Txomin can be contacted at txomin.romero@ehu.eus.</p>"},{"location":"staff/#belen-isla-assistant-director-hpc-resources-lead","title":"Bel\u00e9n Isla - Assistant Director &amp; HPC Resources Lead","text":"<p>Bel\u00e9n focuses on the effective functioning of the DIPC clusters and resource procurement. Her areas of expertise include:</p> <ul> <li>Addressing issues with jobs running on DIPC clusters</li> <li>Handling purchases</li> <li>Assisting with script and queue system inquiries</li> <li>Overseeing the configuration and maintenance of clusters</li> </ul> <p>Bel\u00e9n can be reached at belen.isla@ehu.eus.</p>"},{"location":"staff/#carmen-martin-network-and-security-specialist","title":"Carmen Martin - Network and Security Specialist","text":"<p>Carmen maintains the integrity of our network and ensures its security. Her duties include:</p> <ul> <li>Resolving network access issues</li> <li>Managing web pages</li> <li>Overseeing security protocols</li> <li>Supervising general services.</li> </ul> <p>Carmen can be contacted at carmen_martin@ehu.eus.</p>"},{"location":"staff/#luz-fernandez-helpdesk-and-operations-manager","title":"Luz Fern\u00e1ndez - Helpdesk and Operations Manager","text":"<p>Luz provides support for various technical issues. Her role includes:</p> <ul> <li>Troubleshooting issues with personal computers, email, or printers</li> <li>Assisting with WiFi and network connections</li> <li>Guiding software installations on personal computers</li> <li>Coordinating backups</li> </ul> <p>Luz can be reached at luz_fernandez@ehu.eus.</p>"},{"location":"staff/#diego-lasa-application-specialist-and-hpc-services-lead","title":"Diego Lasa - Application Specialist and HPC Services Lead","text":"<p>Diego supports the DIPC HPC systems and applications. His primary duties include:</p> <ul> <li>Addressing compilation and performance issues on DIPC HPC systems</li> <li>Guiding the installation and use of scientific applications on clusters</li> <li>Resolving issues with jobs running on DIPC clusters</li> <li>Assisting with script and queue system inquiries</li> <li>Providing HPC user support and documentation</li> </ul> <p>Diego can be contacted at diego.lasa@dipc.org.</p>"},{"location":"staff/#daniel-franco-hpc-resources-technician","title":"Daniel Franco - HPC Resources Technician","text":"<p>Daniel provides technical support for the DIPC clusters. His responsibilities include:</p> <ul> <li>Troubleshooting issues with jobs on DIPC clusters</li> <li>Configuration and maintenance of clusters</li> <li>Assisting with script and queue system inquiries</li> <li>Ensuring the maintenance of clusters</li> </ul> <p>Daniel can be reached at daniel.franco@dipc.org.</p>"},{"location":"staff/#jose-caballero-hpc-resources-technician","title":"Jose Caballero - HPC Resources Technician","text":"<p>Jose, much like Daniel, provides technical support for the DIPC clusters. His responsibilities include:</p> <ul> <li>Troubleshooting issues with jobs on DIPC clusters</li> <li>Configuration and maintenance of clusters</li> <li>Assisting with script and queue system inquiries</li> <li>Ensuring the maintenance of clusters</li> </ul> <p>Jose can be contacted at jose.caballero@dipc.org.</p>"},{"location":"staff/#iker-ortiz-de-luzuriaga-application-specialist-and-hpc-services-lead","title":"Iker Ortiz de Luzuriaga - Application Specialist and HPC Services Lead","text":"<p>Iker provides support for DIPC HPC systems and applications. His responsibilities include:</p> <ul> <li>Guiding the installation and use of scientific applications on clusters</li> <li>Resolving issues with jobs running on DIPC clusters</li> <li>Managing cluster accounts</li> <li>Assisting with script and queue system inquiries</li> <li>Providing HPC user support and documentation</li> </ul> <p>Iker can be reached at iker.ortiz@dipc.org.</p>"},{"location":"staff/#julen-suarez-network-and-security-specialist","title":"Julen Suarez - Network and Security Specialist","text":"<p>Julen works on maintaining the security and accessibility of our network. His duties include:</p> <ul> <li>Resolving issues with network access</li> <li>Managing cluster accounts</li> <li>Overseeing web pages</li> <li>Managing security protocols</li> <li>Supervising general services such as ac-02, ac-01, and more</li> </ul> <p>Julen can be contacted at julen.suarez@dipc.org.</p>"}]}